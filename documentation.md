# Submission 1: Credit Card Fraud Detection
Nama: Robiul Awal

Username dicoding: robiulawal

| | Deskripsi |
| ----------- | ----------- |
| Dataset | [Credit Card Fraud Detection Dataset](https://www.kaggle.com/datasets/nelgiriyewithana/credit-card-fraud-detection-dataset-2023) <br> <br> Kumpulan data ini berisi transaksi kartu kredit yang dilakukan oleh pemegang kartu di Eropa pada tahun 2023. Kumpulan data ini terdiri dari lebih dari 550.000 catatan, dan datanya telah dianonimkan untuk melindungi identitas pemegang kartu. Tujuan utama dari kumpulan data ini adalah untuk memfasilitasi pengembangan algoritma dan model deteksi penipuan guna mengidentifikasi transaksi yang berpotensi penipuan. <br> <br> Key features: <br> - id: Unique identifier for each transaction <br> - V1-V28: Anonymized features representing various transaction attributes (e.g., time, location, etc.) <br> - Amount: The transaction amount <br> - Class: Binary label indicating whether the transaction is fraudulent (1) or not (0) |
| Masalah | Penipuan kartu kredit telah menjadi salah satu tantangan utama di era digital yang semakin berkembang. Menurut laporan dari Statista (2023), kerugian akibat penipuan kartu kredit secara global mencapai miliaran dolar setiap tahunnya. Dengan meningkatnya jumlah transaksi online dan adopsi sistem pembayaran elektronik, potensi ancaman dari aktivitas penipuan juga semakin tinggi. Fenomena ini tidak hanya menyebabkan kerugian finansial bagi lembaga keuangan, tetapi juga berdampak pada hilangnya kepercayaan konsumen terhadap keamanan transaksi digital. <br> <br> Penipuan kartu kredit umumnya melibatkan transaksi yang tidak sah tanpa sepengetahuan pemilik kartu. Beberapa contoh modus penipuan meliputi pencurian data kartu melalui skimming, phishing, atau malware. Sistem tradisional berbasis aturan sering kali tidak cukup efektif karena penipu terus mengembangkan metode baru yang semakin canggih dan sulit dideteksi. <br> <br> Deteksi dini aktivitas penipuan sangat penting untuk melindungi pengguna dan institusi keuangan. Namun, salah satu tantangan utama dalam mendeteksi penipuan adalah ketidakseimbangan data (imbalanced dataset), di mana jumlah transaksi yang valid jauh lebih besar dibandingkan transaksi yang mencurigakan. Hal ini dapat memengaruhi akurasi dan performa model deteksi penipuan, sehingga diperlukan pendekatan machine learning yang lebih adaptif dan akurat. |
| Solusi machine learning | Berdasasarkan permasalahan di atas, dapat dirumuskan beberapa solusi machine learning yang dapat dilakukan untuk mengatasi masalah yang ada. Berikut ini solusi-solusi yang dapat dilakukan: <br> - Deteksi Penipuan Kartu Kredit: Bangun model pembelajaran mesin untuk mendeteksi dan mencegah penipuan kartu kredit dengan mengidentifikasi transaksi mencurigakan berdasarkan fitur yang disediakan. <br> - Analisis Kategori Pedagang: Periksa bagaimana kategori pedagang yang berbeda dikaitkan dengan penipuan. <br> - Analisis Jenis Transaksi: Analisis apakah jenis transaksi tertentu lebih rentan terhadap penipuan daripada yang lain. |
| Metode pengolahan | - Data ingestion process. In this process, I use the CsvExampleGen() component provided by TFX. This component was chosen because the dataset we are using has a CSV format.<br> - Data validation process. This process will be created using several components provided by TFX, such as StatisticGen() to create summary statistics, SchemaGen() to create data schemas that accept summary statistics input, and ExampleValidator() to identify anomalies in the dataset.<br> - Data preprocessing process. In this process, I will utilize the Transform() component. At this stage, the researcher creates a function called preprocessing_fn() as a module file in the Transform() component. The preprocessing_fn() function functions to change the text in the Message column to lowercase and perform label encoding in the Category column. |
| Arsitektur model | Model development process. In this process we use the Trainer() component. Before using the Trainer() component to train the model, researchers created several functions to be used as module files and helpers. The functions in this module file consist of input_fn() to prepare the dataset, model_builder() to create a model architecture with the following explanation of the main parts of your model: <br> 1. Input Layer <br> inputs = tf.keras.Input(shape=(1,), name=transformed_name(FEATURE_KEY), dtype=tf.string): The input of this model is expected to be text data (with a string type), which usually contains sentences or documents. <br> 2. Reshaping Input <br> reshaped_narrative = tf.reshape(inputs, [-1]): The input in the form of a tensor with the shape (batch_size, 1) is changed into one dimension, namely a vector form that is easier to process in the next layer. <br> 3. Text Vectorization <br> x = vectorize_layer(reshaped_narrative): TextVectorization layer is used to convert text data into numeric vectors that are easier for the model to process. It converts words in the text into numeric indices based on vocabulary learned from previous data. <br> 4. Embedding Layer <br> x = layers.Embedding(VOCAB_SIZE, embedding_dim, name="embedding")(x): Uses an embedding layer to map word indices to a lower-dimensional vector space (embedding). This allows the model to learn word representations based on their context. <br> 5. Global Average Pooling <br> x = layers.GlobalAveragePooling1D()(x): After the embedding process, global average pooling is used to reduce the output dimensionality and produce a more compact text representation by calculating the average across the time dimension (word sequence).<br> 6. Dense Layers <br> x = layers.Dense(64, activation='relu')(x) and x = layers.Dense(32, activation="relu")(x): Two fully connected (dense) layers are added with decreasing number of neurons. These layers help the model to learn more complex patterns in text data, using ReLU activation function which is known to be effective in accelerating model convergence.<br> 7. Output Layer <br> outputs = layers.Dense(1, activation='sigmoid')(x): The output layer has one neuron with sigmoid activation function, which is suitable for binary classification problems. This output will give a value between 0 and 1, which is then interpreted as the probability for a particular class (e.g., spam or not spam).<br> 8. Compilation <br> This model is compiled using binary crossentropy as the loss function, which is used for binary classification problems. The optimizer used is Adam with a learning rate of 0.01. BinaryAccuracy is used to measure the accuracy of the model in binary classification. <br> There is run_fn() to carry out the model training process according to the expected training parameters, as well as other functions. |
| Metrik evaluasi | Model analysis and validation process. This process will be created using the Resolver and Evaluator components. Here is the explanation: <br> - The Resolver() component is used to perform model analysis and validation. <br> - The Evaluator() component is used to create several configurations to evaluate the model. Before using the Evaluator() component, the researcher set several configurations such as the metrics used to evaluate the model along with the threshold of a metric. The accuracy metric used in this study is BinaryAccuracy. In addition, the researcher also created an interactive visualization of the model evaluation results using the TFMA library. |
| Performa model | Model performance can be seen in the visualization results of the model evaluation produced in the previous stage. Based on the visualization, it can be seen that the accuracy of this model is 0.981 and the loss is only 0.099. Then followed by the number of false_negatives as many as 7 predictions, false_positive as many as 14 predictions, true_negative as many as 155 and true_positive as many as 905. It can be concluded that this model has good performance because it can predict well. |
| Opsi deployment | Deksripsi tentang opsi deployment |
| Web app | Tautan web app yang digunakan untuk mengakses model serving. Contoh: [nama-model](https://model-resiko-kredit.herokuapp.com/v1/models/model-resiko-kredit/metadata)|
| Monitoring | Deksripsi terkait hasil monitoring dari model serving |
